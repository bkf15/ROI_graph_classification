{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as process_labels2, but a binary problem, just high and low risk\n",
    "import torch\n",
    "def process_labels3(o_labels):\n",
    "    l1 = o_labels[\"p1_label\"]\n",
    "    l2 = o_labels[\"p2_label\"]\n",
    "    l3 = o_labels[\"p3_label\"]\n",
    "    l = [l1, l2, l3]\n",
    "    #choose most severe diagnosis\n",
    "    if \"ADH\" in l:\n",
    "        if l.count(\"ADH\") == 3:\n",
    "            return torch.tensor([1, 1])\n",
    "        elif l.count(\"ADH\") == 2:\n",
    "            return torch.tensor([1, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([1, 0.33])\n",
    "\n",
    "    elif \"Flat Epithelial\" in l:\n",
    "        if l.count(\"Flat Epithelial\") == 3:\n",
    "            return torch.tensor([1, 1])\n",
    "        elif l.count(\"Flat Epithelial\") == 2:\n",
    "            return torch.tensor([1, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([1, 0.33])\n",
    "\n",
    "    elif \"Columnar\" in l:\n",
    "        if l.count(\"Columnar\") == 3:\n",
    "            return torch.tensor([0, 1])\n",
    "        elif l.count(\"Columnar\") == 2:\n",
    "            return torch.tensor([0, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([0, 0.33])\n",
    "\n",
    "    elif \"Normal Duct\" in l:\n",
    "        if l.count(\"Normal Duct\") == 3:\n",
    "            return torch.tensor([0, 1])\n",
    "        elif l.count(\"Normal Duct\") == 2:\n",
    "            return torch.tensor([0, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([0, 0.33])     \n",
    "\n",
    "    else:\n",
    "        return torch.tensor([-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other option, just always take the most severe diagnosis, use count for confidence (hopefully get more high risk examples)\n",
    "def process_labels2(o_labels):\n",
    "    l1 = o_labels[\"p1_label\"]\n",
    "    l2 = o_labels[\"p2_label\"]\n",
    "    l3 = o_labels[\"p3_label\"]\n",
    "    l = [l1, l2, l3]\n",
    "    #choose most severe diagnosis\n",
    "    if \"ADH\" in l:\n",
    "        if l.count(\"ADH\") == 3:\n",
    "            return torch.tensor([3, 1])\n",
    "        elif l.count(\"ADH\") == 2:\n",
    "            return torch.tensor([3, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([3, 0.33])\n",
    "\n",
    "    elif \"Flat Epithelial\" in l:\n",
    "        if l.count(\"Flat Epithelial\") == 3:\n",
    "            return torch.tensor([2, 1])\n",
    "        elif l.count(\"Flat Epithelial\") == 2:\n",
    "            return torch.tensor([2, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([2, 0.33])\n",
    "\n",
    "    elif \"Columnar\" in l:\n",
    "        if l.count(\"Columnar\") == 3:\n",
    "            return torch.tensor([1, 1])\n",
    "        elif l.count(\"Columnar\") == 2:\n",
    "            return torch.tensor([1, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([1, 0.33])\n",
    "\n",
    "    elif \"Normal Duct\" in l:\n",
    "        if l.count(\"Normal Duct\") == 3:\n",
    "            return torch.tensor([0, 1])\n",
    "        elif l.count(\"Normal Duct\") == 2:\n",
    "            return torch.tensor([0, 0.66])\n",
    "        else:\n",
    "            return torch.tensor([0, 0.33])     \n",
    "\n",
    "    else:\n",
    "        return torch.tensor([-1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up dataset, just lists of graphs defined as edge pair list and node attribute dict\n",
    "#read all the jsons and add them to Data list\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "json_dir= r\"C:\\Users\\Brian\\Desktop\\AIProject\\roi_graph_jsons\"\n",
    "G = []\n",
    "y = []\n",
    "for roi_json in os.listdir(json_dir):\n",
    "    with open(os.path.join(json_dir, roi_json), 'r') as f:\n",
    "        roi_data = json.loads(f.read())\n",
    "        #Json has following fields:\n",
    "        #  name - name of the image\n",
    "        #  node_features - [num_nodes num_features] matrix of features for each node\n",
    "        #  dist_edge_table - [2 num_edges] edges defined by distance metric\n",
    "        #  labels - dict, which contains p1_label, p2_label, p3_label (roi_data[\"labels\"][\"p1_label\"]\n",
    "        \n",
    "        #process the labels. see the function for more details\n",
    "        label, conf = process_labels2(roi_data[\"labels\"])\n",
    "        if label == -1:\n",
    "            #print(\"Bad sample, no label. Discarding.\")\n",
    "            continue\n",
    "        \n",
    "        y.append(label.item())\n",
    "        \n",
    "        g = []  #represents a single graph\n",
    "        edges = set()         #set of edge pairs\n",
    "        for i in range(len(roi_data[\"dist_edge_table\"][0])):\n",
    "            n1 = roi_data[\"dist_edge_table\"][0][i] + 1\n",
    "            n2 = roi_data[\"dist_edge_table\"][1][i] + 1\n",
    "            edges.add((n1, n2))\n",
    "        \n",
    "        g.append(edges)\n",
    "        x = {}   #node attributes\n",
    "        for i in range(len(roi_data[\"node_features\"])):\n",
    "            x.update({i+1 : roi_data[\"node_features\"][i]})\n",
    "        g.append(x)\n",
    "        g.append({})#example did this\n",
    "        G.append(g)\n",
    "        \n",
    "#print(G[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Done graph propagation\n"
     ]
    }
   ],
   "source": [
    "#actual model\n",
    "\n",
    "from __future__ import print_function\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from grakel.kernels import PropagationAttr\n",
    "\n",
    "y = np.int_(y)\n",
    "# Splits the dataset into a training and a test set\n",
    "G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#resample training so we have even class representation\n",
    "y_train_inv = np.int_(np.ones(len(y_train))-y_train)\n",
    "pos_inds = np.nonzero(y_train)[0]\n",
    "neg_inds = np.nonzero(y_train_inv)[0]\n",
    "\n",
    "pos_inds = np.random.choice(pos_inds, len(neg_inds))\n",
    "G_train_t = []\n",
    "y_train_t = []\n",
    "for i in range(len(pos_inds)):\n",
    "    G_train_t.append(G_train[pos_inds[i]])\n",
    "    y_train_t.append(y_train[pos_inds[i]])\n",
    "for i in range(len(neg_inds)):\n",
    "    G_train_t.append(G_train[neg_inds[i]])\n",
    "    y_train_t.append(y_train[neg_inds[i]])\n",
    "#y_train = y_train_t\n",
    "#G_train = G_train_t\n",
    "\n",
    "# Uses the graphhopper kernel to generate the kernel matrices\n",
    "gk = PropagationAttr(normalize=True)\n",
    "K_train = gk.fit_transform(G_train)\n",
    "K_test = gk.transform(G_test)\n",
    "print(\"Done graph propagation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force test data to be equal class representation\n",
    "y_test_inv = np.int_(np.ones(len(y_test))-y_test)\n",
    "pos_inds = np.nonzero(y_test)[0]\n",
    "neg_inds = np.nonzero(y_test_inv)[0]\n",
    "\n",
    "pos_inds = np.random.choice(pos_inds, len(neg_inds))\n",
    "G_test_t = []\n",
    "y_test_t = []\n",
    "for i in range(len(pos_inds)):\n",
    "    G_test_t.append(G_test[pos_inds[i]])\n",
    "    y_test_t.append(y_test[pos_inds[i]])\n",
    "for i in range(len(neg_inds)):\n",
    "    G_test_t.append(G_test[neg_inds[i]])\n",
    "    y_test_t.append(y_test[neg_inds[i]])\n",
    "#y_test = y_test_t\n",
    "#G_test = G_test_t\n",
    "\n",
    "K_test = gk.transform(G_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.01%\n"
     ]
    }
   ],
   "source": [
    "# Uses the SVM classifier to perform classification\n",
    "clf = SVC(kernel=\"precomputed\", probability=True)\n",
    "clf.fit(K_train, y_train)\n",
    "y_pred_probs = clf.predict_proba(K_test)\n",
    "y_pred = np.argmax(y_pred_probs, 1)\n",
    "\n",
    "# Computes and prints the classification accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", str(round(acc*100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (known=rows, predicted=cols)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.95      0.69       169\n",
      "           1       0.00      0.00      0.00        59\n",
      "           2       0.21      0.07      0.10        44\n",
      "           3       0.42      0.10      0.16        51\n",
      "\n",
      "    accuracy                           0.52       323\n",
      "   macro avg       0.29      0.28      0.24       323\n",
      "weighted avg       0.38      0.52      0.40       323\n",
      "\n",
      "[[160   0   5   4]\n",
      " [ 52   0   5   2]\n",
      " [ 40   0   3   1]\n",
      " [ 45   0   1   5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\brian\\anaconda3\\envs\\pytorch_geometric\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import auc\n",
    "(len(y_test) - np.count_nonzero(y_test)) / (len(y_test))\n",
    "print(\"Confusion matrix (known=rows, predicted=cols)\")\n",
    "#print(confusion_matrix(y_test,y_pred))\n",
    "#print(len(y_pred))\n",
    "#print(\"f1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "#print(\"AUC: \" + str(auc(y_pred_probs, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averge low risk score: 0.9148334882415966\n",
      "Average high risk score: 0.749013617292631\n"
     ]
    }
   ],
   "source": [
    "#compute average confidence scores over the classes\n",
    "avg_hr = 0\n",
    "num_hr = 0\n",
    "avg_lr = 0\n",
    "num_lr = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == 0: #low risk\n",
    "        avg_lr += y_pred_probs[i][0]\n",
    "        num_lr += 1\n",
    "    else:\n",
    "        avg_hr += y_pred_probs[i][1]\n",
    "        num_hr += 1\n",
    "        \n",
    "print(\"Averge low risk score: \" + str(avg_lr / num_lr))\n",
    "print(\"Average high risk score: \" + str(avg_hr / num_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
